---
output:
  word_document: default
  html_document: default
---
#1. Defining the question

## 1.1 Specifying the data analytic objective

Predict which individuals are most likely to click on ads from a cryptography course website


## 1.2 Defining the metric of success

For this study, we will perform conclusive Exploratory Data Analysis to enable us identify individuals who are most likely to click on ads

## 1.3 Understanding the context

A Kenyan entrepreneur has created an online cryptography course and would want to advertise it on her blog. She currently targets audiences originating from various countries. In the past, she ran ads to advertise a related course on the same blog and collected data in the process. Using the data previously collected, she is looking to do a study to identify which individuals are most likely to click on her ads. 

## 1.4 Recording the Experimental Design

1. Loading the data
2. Checking the data
3. Tidying the data
4. Univariate Analysis
5. Bivariate Analysis
6. Challenging the solution
7. Recommendations
8. Follow up questions

# 2. Loading the data set

```{r}
#Loading data
ad <- read.csv('http://bit.ly/IPAdvertisingData')
#Reading head 5
head(ad)
```


```{r}
spaceless <- function(x) {colnames(x) <- gsub(" ", "_", colnames(x));x}
advert <- spaceless(ad)
head(advert)
```

### Checking the summary

```{r}
summary(advert)
```

From the data summary we get the measures of central tendency (median, mean, mode and quantile)

### Checking the top and bottom columns

```{r}
tail(advert)
```

```{r}
head(advert)
```

### Checking the class

```{r}
class(advert)
```

### Structure of the dataset

```{r}
str(advert)
```

```{r}
#Datatypes
sapply(advert, class)
```


#3. Cleaning the dataset

##3.1 Finding missing values

```{r}
colSums(is.na(advert))
```

No missing data was found

## 3.2 Checking for duplicates

```{r}
sum(duplicated(advert))
```

## 3.3 Checking for outliers

```{r}
# Area Income


boxplot(advert$Area.Income)
```

```{r}
# Time spent on site
boxplot(advert$Daily.Time.Spent.on.Site)
```

```{r}
# Age
boxplot(advert$Age)
```

```{r}
# Daily internet usage
boxplot(advert$Daily.Internet.Usage)
```

##3.4 Removing outliers


```{r}
outlier <- 47032 - 1.5 * IQR(advert$Area.Income) 
advert$Area.Income[advert$Area.Income < outlier]<- outlier

boxplot(advert$Area.Income)
```

We remove outliers by limiting extreme values in the statistical data to reduce the effect of possibly spurious outliers

# 4. Exploratory Data Analysis

## 4.1 Univariate Analysis


### Measures of Central Tendency

```{r}
#Selecting the numeric columns
num <- subset(advert, select = -c(Ad.Topic.Line, City,	Male,	Country,	Country, Timestamp))
#Getting the measures of central tendency 
summary(num)
```

### Distribution of data

```{r}
#install.packages("moments")
```

```{r}
library(moments)
```

```{r}
head(num)
```

```{r}
#Checking for skewness
paste("Daily Time_Spent_Skewness: ", paste (skewness(advert$Daily.Time.Spent.on.Site), collapse = ',')) 
paste("Income_Skewness: ", paste (skewness(advert$Area.Income), collapse = ',')) 
paste("Age_Skewness: ", paste (skewness(advert$Age), collapse = ',')) 
paste("Daily_Internet_Usage_Skewness: ", paste (skewness(advert$Daily.Internet.Usage), collapse = ',')) 
```

```{r}
#Checking for kurtosis
paste("Daily Time_Spent_Kurtosis: ", paste (kurtosis(advert$Daily.Time.Spent.on.Site), collapse = ',')) 
paste("Income_Kurtosis: ", paste (kurtosis(advert$Area.Income), collapse = ',')) 
paste("Age_Kurtosis: ", paste (kurtosis(advert$Age), collapse = ',')) 
paste("Daily_Internet_Usage_Kurtosis: ", paste (kurtosis(advert$Daily.Internet.Usage), collapse = ','))
```

```{r}
hist(advert$Age)
hist(advert$Area.Income)
hist(advert$Daily.Internet.Usage)
hist(advert$Daily.Time.Spent.on.Site)
```

### Categorical Data

```{r}
#Which gender is mainly active on the blog?
library(ggplot2)
ggplot(data = advert) +
  geom_bar(mapping = aes(x = Male))

```

Assuming that if male = 1 then we can conclude that more females frequennt the blog more as compared to males

```{r}
#Do most people clickon ads or not?

ggplot(data = advert) +
  geom_bar(mapping = aes(x = Clicked.on.Ad))
```

## 4.2 Bivariate Analysis

```{r}
# install.packages("corrplot")

library(corrplot)
```

```{r}
#Get the correlation matrix
res = cor(num)
#Plotting a correlation plot

corrplot(res, method="color",addCoef.col = "black", 
         tl.col="black", tl.srt=45)
```

```{r}
#Change datattypes
advert$Male <- as.factor(advert$Male)
advert$Clicked.on.Ad <- as.factor(advert$Clicked.on.Ad)
#Checking datatypes
sapply(advert, class)
```




```{r}
#install.packages("tidyverse")
library(ggplot2)

ggplot(advert, 
       aes(x = Clicked.on.Ad, 
           fill = Male)) + 
  geom_bar(position = "stack")

```

# 5. Feature Engineering

```{r}
head(advert)
```

```{r}
library(dplyr)
mod.data <- select(advert, -c(5,6,8,9))
head(mod.data)
```

```{r}
#
library(caret)

#Create an index for data partitioning
set.seed(42)
index <- createDataPartition(mod.data$Clicked.on.Ad, p = 0.80, list = FALSE)
```

```{r}
#Using the indexes to split data into test and train set
dat.train <- mod.data[index, ]
dat.test <- mod.data[-index, ]
```

# 6. Decision Trees

```{r}
#Installing packages to be used for modelling
#install.packages("rpart")
library(rpart)
#install.packages("e1071")
library(e1071)
```

```{r}
#Fitting in the decision tree
TreeFit <- rpart(Clicked.on.Ad ~ ., data = dat.train)

#Factor the Clicked.on.Ad vector in the test dataset
dat.test$Clicked.on.Ad <- factor(dat.test$Clicked.on.Ad)

#Using model to predict
TreePredict <- predict(TreeFit, newdata = dat.test, type = "class")
confusionMatrix(TreePredict, dat.test$Clicked.on.Ad)
``` 

Decision trees had a 95% accuracy score.

# 7. KNN

```{R}
#Fitting model to training dataset
#Also we scale and center our data
knnModel <- train(Clicked.on.Ad ~ ., data = dat.train, method = "knn", preProcess = c("center", "scale"))

#Using the model to predict
knnPredict <- predict(knnModel, newdata = dat.test)

#Printing out the confusion matrix and statistics
confusionMatrix(knnPredict, dat.test$Clicked.on.Ad)
```

 KNN performs at an accuracy of 94.5%.

```{R}
#Installing and running the kernlab package
#install.packages("kernlab")
library(kernlab)
```

```{R}
#controling all the computational overheads using traincontrol
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)

#We fit the model using the linear kernel
#Data is also scaled and centered
svm_Linear <- train(Clicked.on.Ad ~., data = dat.train, method = "svmLinear",
trControl=trctrl,
preProcess = c("center", "scale"),
tuneLength = 10)

# We then check the result of our train() model 
svm_Linear

#We then predict
test_pred <- predict(svm_Linear, newdata = dat.test)
test_pred

#Print the confusion matrix and statistics
confusionMatrix(table(test_pred, dat.test$Clicked.on.Ad))

```

As compared to KNN and Decision Trees, the SVM linear kernel model performs the best.It has an accuracy score of 96%

# Conclusion

In conclusion, we advice the owner of the blog to use an SVM model with a linear kernel to predict whether users of the blog will click on an ad or not






